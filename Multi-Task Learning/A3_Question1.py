# -*- coding: utf-8 -*-
"""M22MA003_PA3_Question1.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/14p-sY5dOoVe9gWPn4vTzN7mhqYSPnTZN
"""

import torch
import torch.nn as nn
import torch.nn.functional as F
import torchvision
import torchvision.transforms as transforms
import matplotlib.pyplot as plt
import numpy as np
from torch.utils.data import DataLoader
# Device configuration
device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
import os
from torch.utils.data.dataloader import default_collate

# Import libraries
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
from datetime import datetime as dt
import torch.nn.functional as F
import torch
from torch import optim, nn
from torch.utils.data import DataLoader, TensorDataset, Dataset
from torchvision.utils import make_grid
from torchvision import transforms as T
from torchvision import models, datasets
device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
# from ignite.engine import Events, create_supervised_trainer, create_supervised_evaluator
# from ignite.metrics import Accuracy, Loss, Precision, Recall
# from ignite.handlers import LRScheduler, ModelCheckpoint, global_step_from_engine
# from ignite.contrib.handlers import ProgressBar, TensorboardLogger
# import ignite.contrib.engines.common as common

# import opendatasets as od
import os
from random import randint
import urllib
import zipfile
import gc
from torchvision.models import resnet18

from google.colab import drive
drive.mount('/content/drive')

!unzip -qq '/content/drive/MyDrive/CelebA_Dataset.zip'

# Define the path to your input file and output file
input_file_path = '/content/list_attr_celeba.txt'
output_file_path = '/content/header.txt'

# Read the first two lines from the input file
with open(input_file_path, 'r') as input_file:
    lines = input_file.readlines()[:2]  # Read the first two lines

# Check the number of words in the first line
num_words_first_line = len(lines[0].split())

# Check if the first line contains less than 40 words
if num_words_first_line < 40:
    # Combine the first line with the second line
    merged_line = lines[0].strip() + ' ' + lines[1].strip()

    # Write the merged line to the output file
    with open(output_file_path, 'w') as output_file:
        output_file.write(merged_line + '\n')

    print("The first line was combined with the second line and saved to the output file.")
else:
    print("The first line contains 40 or more words, no action taken.")

# Define the path to your file
file_path = '/content/list_attr_celeba.txt'

# Define the characters to replace and their replacement
old_char = '  1'
new_char = ' 1'

# Read the file
with open(file_path, 'r') as file:
    file_content = file.read()

# Replace characters in the file content
new_file_content = file_content.replace(old_char, new_char)

# Write the updated content back to the file
with open(file_path, 'w') as file:
    file.write(new_file_content)

print(f"Characters '{old_char}' have been replaced with '{new_char}' in the file.")

header_file_path = '/content/header.txt'

# Read the header from the header file
with open(header_file_path, 'r') as header_file:
    header = header_file.read().strip().split()

print(header)
csv_file_path = '/content/list_attr_celeba.txt'

# Read the CSV file with space as delimiter
df = pd.read_csv(csv_file_path, sep=" ", skiprows=2,names=header)

# Print the DataFrame
print(df)

columns_to_include = ['Bags_Under_Eyes', 'Big_Lips', 'Black_Hair', 'Blond_Hair', 'Chubby', 'Eyeglasses', 'Mustache', 'Receding_Hairline']

# Save the DataFrame with only the specified columns to a CSV file
df[columns_to_include].to_csv('output.csv', index=False)

dataf = pd.read_csv('list_attr_celeba.txt', skiprows = 1, usecols = columns_to_include, sep = "\s+", index_col = 0)
dataf

dataf.replace(-1, 0, inplace = True)
dataf

split = int(len(dataf)*0.7)

train_df = dataf.iloc[0:split, :]
test_df = dataf.iloc[split:, :]

train_df,test_df

import os
import torch
import PIL
from torch.utils.data import Dataset

class ImageAttributeDataset(Dataset):
    def __init__(self, df, image_dir, transform=None):
        self.image_dir = image_dir
        self.y = df.values
        self.image_ = df.index.values
        self.transform = transform

        # self.image_paths, self.attributes = self._load_attributes()

    def __getitem__(self, idx):
        img_path = os.path.join(self.image_dir,self.image_[idx])
        img = PIL.Image.open(os.path.join(self.image_dir,self.image_[idx]))
        # image_path = self.image_paths[idx]
        # image = Image.open(image_path).convert('RGB')

        if self.transform is not None:
            img = self.transform(img)
        attributes = self.y[idx]
        attributes = torch.from_numpy(attributes)

        return img, attributes
        # attributes = self.attributes[idx]

        # return image, attributes
    def __len__(self):
        return self.y.shape[0]
    # def _load_attributes(self):
    #     image_paths = []
    #     attributes = []

    #     with open(self.attribute_file, 'r') as f:
    #         lines = f.readlines()
    #         for line in lines[1:87]:  # Skip the header row
    #             items = line.strip().split(',')
    #             image_path = os.path.join(self.image_dir, items[0])
    #             attribute = [int(item) for item in items[1:]]  # Assumes attributes are integers
    #             image_paths.append(image_path)
    #             attributes.append(attribute)
    #         print(attributes)
    #     return image_paths, attributes
batch_size = 128

transformation = transforms.Compose([transforms.Resize((64, 64)),transforms.ToTensor()])
image_path='/content/img_align_celeba'
train_set = ImageAttributeDataset(train_df, image_path, transform = transformation)
dataloader_train = DataLoader(train_set, batch_size=batch_size, shuffle=False, collate_fn=lambda x: tuple(x_.to(device) for x_ in default_collate(x)))
test_set = ImageAttributeDataset(test_df, image_path, transform = transformation)
dataloader_test = DataLoader(test_set, batch_size=batch_size, shuffle=False, collate_fn=lambda x: tuple(x_.to(device) for x_ in default_collate(x)))

len(dataloader_train)

dataiter = iter(dataloader_train)
images, labels = next(dataiter)
print(labels[0:3])
images_cpu = images.cpu()
def imshow(img):
    # img = img / 2 + 0.5  # unnormalize
    npimg = img.numpy()
    plt.imshow(np.transpose(npimg, (1, 2, 0)))
    plt.show()
# show images
imshow(torchvision.utils.make_grid(images_cpu))

def plot_curve(epochs, loss_train_list, loss_test_list, accuracy_train_list, Bags_Under_Eyes_train_list,Big_Lips_train_list,Black_Hair_train_list,Blond_Hair_train_list,Chubby_train_list,Eyeglasses_train_list,Mustache_train_list,Receding_Hairline_train_list,\
accuracy_test_list, Bags_Under_Eyes_test_list,Big_Lips_test_list,Black_Hair_test_list,Blond_Hair_test_list,Chubby_test_list,Eyeglasses_test_list,Mustache_test_list,Receding_Hairline_test_list):
    
    plt.figure(figsize=(23, 7))

    plt.subplot(1, 3, 1)
    plt.plot(epochs, loss_train_list, label='train_loss')
    plt.plot(epochs, loss_test_list, label='test_loss')
    plt.title('Epoch vs Loss')
    plt.xlabel('Epochs')
    plt.legend()

    # Bags_Under_Eyes', 'Big_Lips', 'Black_Hair', 'Blond_Hair', 'Chubby', 'Eyeglasses', 'Mustache', 'Receding_Hairline
    plt.subplot(1, 3, 2)
    plt.plot(epochs, accuracy_train_list, label='overall accuracy')
    plt.plot(epochs, Bags_Under_Eyes_train_list, label='Bags_Under_Eyes: train accuracy')
    plt.plot(epochs, Big_Lips_train_list, label='Big_Lips: train_accuracy')
    plt.plot(epochs, Black_Hair_train_list, label='Black_Hair: train_accuracy')
    plt.plot(epochs, Blond_Hair_train_list, label='Blond_Hair: train_accuracy')
    plt.plot(epochs, Chubby_train_list, label='Chubby: train_accuracy')
    plt.plot(epochs, Eyeglasses_train_list, label='Eyeglasses: train_accuracy')
    plt.plot(epochs, Mustache_train_list, label='Mustache: train_accuracy')
    plt.plot(epochs, Receding_Hairline_train_list, label='Receding_Hairline: train_accuracy')

    plt.title('Epoch vs Train Accuracy')
    plt.xlabel('Epochs')
    plt.legend()

    plt.subplot(1, 3, 3)
    plt.plot(epochs, accuracy_test_list, label='overall accuracy')
    plt.plot(epochs, Bags_Under_Eyes_test_list, label='Bags_Under_Eyes: test accuracy')
    plt.plot(epochs, Big_Lips_test_list, label='Big_Lips: test_accuracy')
    plt.plot(epochs, Black_Hair_test_list, label='Black_Hair: test_accuracy')
    plt.plot(epochs, Blond_Hair_test_list, label='Blond_Hair: test_accuracy')
    plt.plot(epochs, Chubby_test_list, label='Chubby: test_accuracy')
    plt.plot(epochs, Eyeglasses_test_list, label='Eyeglasses: test_accuracy')
    plt.plot(epochs, Mustache_test_list, label='Mustache: test_accuracy')
    plt.plot(epochs, Receding_Hairline_test_list, label='Receding_Hairline: test_accuracy')


    plt.title('Epoch vs Test Accuracy')
    plt.xlabel('Epochs')
    plt.legend()

    plt.show()

def check_acc(true, pred):
  val = (torch.eq(true, pred.argmax(dim = 1)).sum().item())
  return (val/ len(pred)) * 100

criterion = nn.CrossEntropyLoss()
learning_rate=0.001





# Bags_Under_Eyes', 'Big_Lips', 'Black_Hair', 'Blond_Hair', 'Chubby', 'Eyeglasses', 'Mustache', 'Receding_Hairline

class ResNet18(nn.Module):
  def __init__(self):
    super().__init__()
    self.resmodel = resnet18(weights = None)
    self.resmodel.t_bags_under_eyes = nn.Linear(self.resmodel.fc.out_features, 2)
    self.resmodel.t_big_lips = nn.Linear(self.resmodel.fc.out_features, 2)
    self.resmodel.t_black_hair = nn.Linear(self.resmodel.fc.out_features, 2)
    self.resmodel.t_blond_hair = nn.Linear(self.resmodel.fc.out_features, 2)
    self.resmodel.t_chubby = nn.Linear(self.resmodel.fc.out_features, 2)
    self.resmodel.t_eyeglasses = nn.Linear(self.resmodel.fc.out_features, 2)
    self.resmodel.t_mustache = nn.Linear(self.resmodel.fc.out_features, 2)
    self.resmodel.t_receding_hairline = nn.Linear(self.resmodel.fc.out_features, 2)

    self.Relu = nn.ReLU()

  def forward(self, x):
    x = self.Relu(self.resmodel(x))
    bags_under_eyes = self.Relu(self.resmodel.t_bags_under_eyes(x))
    big_lips = self.Relu(self.resmodel.t_big_lips(x))
    black_hair = self.Relu(self.resmodel.t_black_hair(x))
    blond_hair = self.Relu(self.resmodel.t_blond_hair(x))
    chubby = self.Relu(self.resmodel.t_chubby(x))
    eyeglasses = self.Relu(self.resmodel.t_eyeglasses(x))
    mustache = self.Relu(self.resmodel.t_mustache(x))
    receding_hairline = self.Relu(self.resmodel.t_receding_hairline(x))

    return bags_under_eyes, big_lips, black_hair, blond_hair, chubby, eyeglasses, mustache, receding_hairline

model = ResNet18().to(device)
optimizer = optim.Adam(model.parameters(), lr = learning_rate)
model

def model_evaluation(model, criterion, optimizer, num_epochs, dataloader_train, dataloader_test):
  

  accuracy_train_list, Bags_Under_Eyes_train_list,Big_Lips_train_list,Black_Hair_train_list,Blond_Hair_train_list,Chubby_train_list,Eyeglasses_train_list,Mustache_train_list,Receding_Hairline_train_list = [], [], [], [], [], [], [], [], []
  accuracy_test_list, Bags_Under_Eyes_test_list,Big_Lips_test_list,Black_Hair_test_list,Blond_Hair_test_list,Chubby_test_list,Eyeglasses_test_list,Mustache_test_list,Receding_Hairline_test_list= [], [], [], [], [], [], [], [], []
  epoch_list,loss_test_list,loss_train_list = [], [], []

  for epoch in range(num_epochs):

    model.train()
    loss_train, loss_test = 0, 0
    accuracy_train, accuracy_0, accuracy_1, accuracy_2, accuracy_3, accuracy_4, accuracy_5, accuracy_6, accuracy_7 = 0, 0, 0, 0, 0, 0, 0, 0, 0
    aaccuracy_test, accuracy_t_0, accuracy_t_1, accuracy_t_2, accuracy_t_3, accuracy_t_4, accuracy_t_5, accuracy_t_6, accuracy_t_7 = 0, 0, 0, 0, 0, 0, 0, 0, 0

    for batch, (images, label) in enumerate(dataloader_train):
      length = len(dataloader_train)
      optimizer.zero_grad()
      output_0, output_1, output_2, output_3, output_4, output_5, output_6, output_7 = model(images)
      
      l_0 = criterion(output_0, label[:, 0])
      l_1 = criterion(output_1, label[:, 1])
      l_2 = criterion(output_2, label[:, 2])
      l_3 = criterion(output_3, label[:, 3])
      l_4 = criterion(output_4, label[:, 4])
      l_5 = criterion(output_5, label[:, 5])
      l_6 = criterion(output_6, label[:, 6])
      l_7 = criterion(output_7, label[:, 7])

      loss = l_0 + l_1 + l_2 + l_3 + l_4 + l_5 + l_6 + l_7


      accuracy_0 = accuracy_0 + check_acc(label[:, 0],output_0)
      accuracy_1 = accuracy_1 + check_acc(label[:, 1],output_1)
      accuracy_2 = accuracy_2 + check_acc(label[:, 2],output_2)
      accuracy_3 = accuracy_3 + check_acc(label[:, 3],output_3)
      accuracy_4 = accuracy_4 + check_acc(label[:, 4],output_4)
      accuracy_5 = accuracy_5 + check_acc(label[:, 5],output_5)
      accuracy_6 = accuracy_6 + check_acc(label[:, 6],output_6)
      accuracy_7 = accuracy_7 + check_acc(label[:, 7],output_7)
      
      loss.backward()

      optimizer.step()

      loss_train = loss_train + loss

      del output_0, output_1, output_2, output_3, output_4, output_5, output_6, output_7, loss

      if device == torch.device("cuda"):
        gc.collect()
        torch.cuda.empty_cache()


    loss_train = loss_train / length
    accuracy_0 = accuracy_0 / length
    accuracy_1 = accuracy_1 / length
    accuracy_2 = accuracy_2 / length
    accuracy_3 = accuracy_3 / length
    accuracy_4 = accuracy_4 / length
    accuracy_5 = accuracy_5 / length
    accuracy_6 = accuracy_6 / length
    accuracy_7 = accuracy_7 / length

    accuracy_train = (accuracy_0 + accuracy_1 + accuracy_2 + accuracy_3 + accuracy_4 + accuracy_5 + accuracy_6 + accuracy_7)/8
    

    
    model.eval()
    length_test = len(dataloader_test)
    with torch.inference_mode():
      for image_test, label_test in dataloader_test:
      
        test_pred0, test_pred1, test_pred2, test_pred3, test_pred4, test_pred5, test_pred6, test_pred7 = model(image_test)
        
        l_0 = criterion(test_pred0, label_test[:, 0])
        l_1 = criterion(test_pred1, label_test[:, 1])
        l_2 = criterion(test_pred2, label_test[:, 2])
        l_3 = criterion(test_pred3, label_test[:, 3])
        l_4 = criterion(test_pred4, label_test[:, 4])
        l_5 = criterion(test_pred5, label_test[:, 5])
        l_6 = criterion(test_pred6, label_test[:, 6])
        l_7 = criterion(test_pred7, label_test[:, 7])

        loss = l_0 + l_1 + l_2 + l_3 + l_4 + l_5 + l_6 + l_7

        accuracy_t_0 = accuracy_t_0 + check_acc(label_test[:, 0],test_pred0)
        accuracy_t_1 = accuracy_t_1 + check_acc(label_test[:, 1],test_pred1)
        accuracy_t_2 = accuracy_t_2 + check_acc(label_test[:, 2],test_pred2)
        accuracy_t_3 = accuracy_t_3 + check_acc(label_test[:, 3],test_pred3)
        accuracy_t_4 = accuracy_t_4 + check_acc(label_test[:, 4],test_pred4)
        accuracy_t_5 = accuracy_t_5 + check_acc(label_test[:, 5],test_pred5)
        accuracy_t_6 = accuracy_t_6 + check_acc(label_test[:, 6],test_pred6)
        accuracy_t_7 = accuracy_t_7 + check_acc(label_test[:, 7],test_pred7)

        loss_test += loss

        del test_pred0, test_pred1, test_pred2, test_pred3, test_pred4, test_pred5, test_pred6, test_pred7, loss

        if device == torch.device("cuda"):
          gc.collect()
          torch.cuda.empty_cache()

    accuracy_t_0 =accuracy_t_0/length_test
    accuracy_t_1 =accuracy_t_1/length_test
    accuracy_t_2 =accuracy_t_2/length_test
    accuracy_t_3 =accuracy_t_3/length_test
    accuracy_t_4 =accuracy_t_4/length_test
    accuracy_t_5 =accuracy_t_5/length_test
    accuracy_t_6 =accuracy_t_6/length_test
    accuracy_t_7 =accuracy_t_7/length_test

    accuracy_test = (accuracy_t_0 + accuracy_t_1 + accuracy_t_2 + accuracy_t_3 + accuracy_t_4 + accuracy_t_5 + accuracy_t_6 + accuracy_t_7)/8

    loss_test = loss_test / length_test

    print(f"Epochs: {epoch}")
    print(f"\tTrain l_: {loss_train:0.2f}")
    print(f"Train Accuarcy is : {accuracy_train:.2f}")
    print(f"Bags_Under_Eyes accuracy is : {accuracy_0 :.2f} , Big_Lips accuracy is : {accuracy_1 :.2f} , Black_Hair accuracy is : {accuracy_2 :.2f} , Blond_Hair accuracy is : {accuracy_3 :.2f} ")
    print(f"Chubby accuracy is : {accuracy_4 :.2f} , Eyeglasses accuracy is : {accuracy_5 :.2f} , Mustache accuracy is : {accuracy_6 :.2f} , Receding_Hairline accuracy is : {accuracy_7 :.2f}  ")
    print(f"\tTest Loss is: {loss_test:0.2f}")
    print(f"\tTest Accuracy: {accuracy_test:0.2f}")
    print(f"Bags_Under_Eyes accuracy is : {accuracy_t_0 :.2f} , Big_Lips accuracy is : {accuracy_t_1 :.2f} , Black_Hair accuracy is : {accuracy_t_2 :.2f} , Blond_Hair accuracy is : {accuracy_t_3 :.2f} ")
    print(f"Chubby accuracy is : {accuracy_t_4 :.2f} , Eyeglasses accuracy is : {accuracy_t_5 :.2f} , Mustache accuracy is : {accuracy_t_6 :.2f} , Receding_Hairline accuracy is : {accuracy_t_7 :.2f} ")


    epoch_list.append(epoch)
    loss_train_list.append(loss_train)
    loss_test_list.append(loss_test)

  # Bags_Under_Eyes_train_list,Big_Lips_train_list,Black_Hair_train_list,Blond_Hair_train_list,Chubby_train_list,Eyeglasses_train_list,Mustache_train_list,Receding_Hairline_train_list
    
    accuracy_train_list.append(accuracy_train)
    Bags_Under_Eyes_train_list.append(accuracy_0)
    Big_Lips_train_list.append(accuracy_1)
    Black_Hair_train_list.append(accuracy_2)
    Blond_Hair_train_list.append(accuracy_3)
    Chubby_train_list.append(accuracy_4)
    Eyeglasses_train_list.append(accuracy_5)
    Mustache_train_list.append(accuracy_6)
    Receding_Hairline_train_list.append(accuracy_7)

    accuracy_test_list.append(accuracy_test)
    Bags_Under_Eyes_test_list.append(accuracy_t_0)
    Big_Lips_test_list.append(accuracy_t_1)
    Black_Hair_test_list.append(accuracy_t_2)
    Blond_Hair_test_list.append(accuracy_t_3)
    Chubby_test_list.append(accuracy_t_4)
    Eyeglasses_test_list.append(accuracy_t_5)
    Mustache_test_list.append(accuracy_t_6)
    Receding_Hairline_test_list.append(accuracy_t_7)
  
  loss_train_list = torch.tensor(loss_train_list).cpu().numpy()
  loss_test_list = torch.tensor(loss_test_list).cpu().numpy()

  accuracy_train_list = torch.tensor(accuracy_train_list).cpu().numpy()
  Bags_Under_Eyes_train_list= torch.tensor(Bags_Under_Eyes_train_list).cpu().numpy()
  Big_Lips_train_list= torch.tensor(Big_Lips_train_list).cpu().numpy()
  Black_Hair_train_list= torch.tensor(Black_Hair_train_list).cpu().numpy()
  Blond_Hair_train_list= torch.tensor(Blond_Hair_train_list).cpu().numpy()
  Chubby_train_list= torch.tensor(Chubby_train_list).cpu().numpy()
  Eyeglasses_train_list= torch.tensor(Eyeglasses_train_list).cpu().numpy()
  Mustache_train_list= torch.tensor(Mustache_train_list).cpu().numpy()
  Receding_Hairline_train_list= torch.tensor(Receding_Hairline_train_list).cpu().numpy()

  accuracy_test_list = torch.tensor(accuracy_test_list).cpu().numpy()
  Bags_Under_Eyes_test_list= torch.tensor(Bags_Under_Eyes_test_list).cpu().numpy()
  Big_Lips_test_list= torch.tensor(Big_Lips_test_list).cpu().numpy()
  Black_Hair_test_list= torch.tensor(Black_Hair_test_list).cpu().numpy()
  Blond_Hair_test_list= torch.tensor(Blond_Hair_test_list).cpu().numpy()
  Chubby_test_list= torch.tensor(Chubby_test_list).cpu().numpy()
  Eyeglasses_test_list= torch.tensor(Eyeglasses_test_list).cpu().numpy()
  Mustache_test_list= torch.tensor(Mustache_test_list).cpu().numpy()
  Receding_Hairline_test_list= torch.tensor(Receding_Hairline_test_list).cpu().numpy()


  if device == torch.device("cuda"):
    gc.collect()
    torch.cuda.empty_cache()
  
  return epoch_list, loss_train_list, loss_test_list, accuracy_train_list, Bags_Under_Eyes_train_list,Big_Lips_train_list,Black_Hair_train_list,Blond_Hair_train_list,Chubby_train_list,Eyeglasses_train_list,Mustache_train_list,Receding_Hairline_train_list,\
  accuracy_test_list, Bags_Under_Eyes_test_list,Big_Lips_test_list,Black_Hair_test_list,Blond_Hair_test_list,Chubby_test_list,Eyeglasses_test_list,Mustache_test_list,Receding_Hairline_test_list

num_epochs=5
epoch_list, loss_train_list, loss_test_list, accuracy_train_list, Bags_Under_Eyes_train_list,Big_Lips_train_list,Black_Hair_train_list,Blond_Hair_train_list,Chubby_train_list,Eyeglasses_train_list,Mustache_train_list,Receding_Hairline_train_list,\
accuracy_test_list, Bags_Under_Eyes_test_list,Big_Lips_test_list,Black_Hair_test_list,Blond_Hair_test_list,Chubby_test_list,Eyeglasses_test_list,Mustache_test_list,Receding_Hairline_test_list = model_evaluation(model, criterion, optimizer, num_epochs, dataloader_train, dataloader_test)

plot_curve(epoch_list, loss_train_list, loss_test_list, accuracy_train_list, Bags_Under_Eyes_train_list,Big_Lips_train_list,Black_Hair_train_list,Blond_Hair_train_list,Chubby_train_list,Eyeglasses_train_list,Mustache_train_list,Receding_Hairline_train_list,\
accuracy_test_list, Bags_Under_Eyes_test_list,Big_Lips_test_list,Black_Hair_test_list,Blond_Hair_test_list,Chubby_test_list,Eyeglasses_test_list,Mustache_test_list,Receding_Hairline_test_list)

