# -*- coding: utf-8 -*-
"""M22MA003_PA5_Q1.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1Y_rE-i7UnFepy0ouNcqZ1VtTu5ELAUte
"""

from __future__ import print_function
import os
import random
import torch
import torch.nn as nn
import torch.nn.parallel
import torch.backends.cudnn as cudnn
import torch.optim as optim
import torch.utils.data
import torchvision
import matplotlib.pyplot as plt
import matplotlib.animation as animation
import torchvision.datasets as td
from IPython.display import HTML
import torch.nn.init as init
import torch.nn.functional as F
os.environ['CUDA_LAUNCH_BLOCKING'] = '1'
import torchvision.transforms as transforms
import torchvision.utils as vutils
import numpy as np
from torch.utils.data import DataLoader
from torchvision.io import read_image
import torchvision.models as models


manualSeed = 999

print("Seed Value: ", manualSeed)
random.seed(manualSeed)
torch.manual_seed(manualSeed)

device = 'cuda' if torch.cuda.is_available() else 'cpu'
device

latent_dim = 100
cuda_count = 1
img_size = 64
batch = 128
epochs = 10
val_beta_1 = 0.5
list_Gen = []
list_Dis = []
lr = 0.0002
device = torch.device("cuda:0" if (torch.cuda.is_available() and cuda_count > 0) else "cpu")
criterion = nn.BCELoss()
y_true = 1.
y_fake = 0.
img_list = []
check = 0

transforms=transforms.Compose([transforms.Resize(img_size),transforms.CenterCrop(img_size),transforms.ToTensor(),transforms.Normalize((0.5,), (0.5,))])
dataset = td.EMNIST(root="data", split='balanced', train=False, download=True, transform=transforms)

dataloader = DataLoader(dataset, shuffle=True, batch_size=batch)

dataiter = iter(dataloader)
images, labels = next(dataiter)
images_cpu = images.cpu()
def imshow(img):
    npimg = img.numpy()
    plt.imshow(np.transpose(vutils.make_grid(images[0].to(device)[:10], padding=2, normalize=True).cpu(),(1,2,0)))
    plt.show()
imshow(torchvision.utils.make_grid(images_cpu))

def plot_loss(list_Gen,list_Dis):
    plt.figure(figsize=(5,5))
    plt.title("Generator and Discriminator Loss During Training")
    plt.plot(list_Gen,label="G")
    plt.plot(list_Dis,label="D")
    plt.xlabel("iterations")
    plt.ylabel("Loss")
    plt.legend()
    plt.show()

def w_initialisation(mif):
    classname = mif.__class__.__name__
    if classname.find('Conv') != -1:
        nn.init.normal_(mif.weight.data, 0.0, 0.02)
    elif classname.find('BatchNorm') != -1:
        nn.init.normal_(mif.weight.data, 1.0, 0.02)
        nn.init.constant_(mif.bias.data, 0)

latent_dim = 100
num_gen_features = 64
num_channels = 3
class ResGenerator(nn.Module):
    def __init__(self, num_gpu):
        super(ResGenerator, self).__init__()
        self.num_gpu = num_gpu
        self.main = nn.Sequential(
            nn.ConvTranspose2d( latent_dim, num_gen_features * 8, 4, 1, 0, bias=False),
            nn.BatchNorm2d(num_gen_features * 8), nn.ReLU(True),
            nn.ConvTranspose2d(num_gen_features * 8, num_gen_features * 4, 4, 2, 1, bias=False),
            nn.BatchNorm2d(num_gen_features * 4), nn.ReLU(True),
            nn.ConvTranspose2d(num_gen_features * 4, num_gen_features * 2, 4, 2, 1, bias=False),
            nn.BatchNorm2d(num_gen_features * 2), nn.ReLU(True),
            nn.ConvTranspose2d(num_gen_features * 2, num_gen_features, 4, 2, 1, bias=False),
            nn.BatchNorm2d(num_gen_features), nn.ReLU(True),
            nn.ConvTranspose2d(num_gen_features, num_channels, 4, 2, 1, bias=False), nn.Tanh()
        )

    def forward(self, input):
        return self.main(input)

import torch
import torch.nn as nn
import torch.nn.functional as F

# Residual block
class ResidualBlock(nn.Module):
    def __init__(self, in_planes, planes, stride=1):
        super(ResidualBlock, self).__init__()
        self.conv1 = nn.Conv2d(in_planes, planes, kernel_size=3, stride=stride, padding=1, bias=False)
        self.bn1 = nn.BatchNorm2d(planes)
        self.conv2 = nn.Conv2d(planes, planes, kernel_size=3, stride=1, padding=1, bias=False)
        self.bn2 = nn.BatchNorm2d(planes)

        self.shortcut = nn.Sequential()
        if stride != 1 or in_planes != planes:
            self.shortcut = nn.Sequential(
                nn.Conv2d(in_planes, planes, kernel_size=1, stride=stride, bias=False),
                nn.BatchNorm2d(planes)
            )

    def forward(self, x):
        out = F.relu(self.bn1(self.conv1(x)))
        out = self.bn2(self.conv2(out))
        out += self.shortcut(x)
        out = F.relu(out)
        return out


# ResNet-56 model
class ResNet56(nn.Module):
    def __init__(self, num_classes=10):
        super(ResNet56, self).__init__()
        self.in_planes = 16

        self.conv1 = nn.Conv2d(1, 16, kernel_size=3, stride=1, padding=1, bias=False)
        self.bn1 = nn.BatchNorm2d(16)
        self.layer1 = self._make_layer(16, 16, 9, stride=1)
        self.layer2 = self._make_layer(16, 32, 9, stride=2)
        self.layer3 = self._make_layer(32, 64, 9, stride=2)
        self.avgpool = nn.AdaptiveAvgPool2d(1)
        self.fc = nn.Linear(64, num_classes)
        self.sig = nn.Sigmoid()

    def _make_layer(self, in_planes, planes, num_blocks, stride):
        layers = []
        layers.append(ResidualBlock(in_planes, planes, stride))
        for _ in range(1, num_blocks):
            layers.append(ResidualBlock(planes, planes, stride=1))
        return nn.Sequential(*layers)

    def forward(self, x):
        out = F.relu(self.bn1(self.conv1(x)))
        out = self.layer1(out)
        out = self.layer2(out)
        out = self.layer3(out)
        out = self.avgpool(out)
        out = out.view(out.size(0), -1)
        out = self.sig(self.fc(out))
        return out

def resnet56():
    return ResNet56(num_classes=1)

modelGen = ResGenerator(cuda_count).to(device)

if (device.type == 'cuda') and (cuda_count > 1):
    modelGen = nn.DataParallel(modelGen, list(range(cuda_count)))

modelGen.apply(w_initialisation)

print(modelGen)

# Discriminator Code

class ResDiscriminator(nn.Module):
    def __init__(self, cuda_count):
        super(ResDiscriminator, self).__init__()
        self.cuda_count = cuda_count
        self.resnet = resnet56()

    def forward(self, input):
        # print(input.shape)
        features = self.resnet(input)
        # print(features.shape)
        
        features = features.flatten()
        # print(features.shape)
        out = features.view(-1, 1).squeeze(1)
        # print(out.shape)
        return out

# Create the Discriminator
modelDis = ResDiscriminator(cuda_count).to(device)

# Handle multi-GPU if desired
if (device.type == 'cuda') and (cuda_count > 1):
    modelDis = nn.DataParallel(modelDis, list(range(cuda_count)))


print(modelDis)

optimDis = optim.Adam(modelDis.parameters(), lr=lr, betas=(val_beta_1, 0.999))
optimGen = optim.Adam(modelGen.parameters(), lr=lr, betas=(val_beta_1, 0.999))

noise = torch.randn(10, latent_dim, 1, 1, device=device)

# Commented out IPython magic to ensure Python compatibility.

for epoch in range(epochs):
    for num_batch, data in enumerate(dataloader, 0):

        modelDis.zero_grad()
        input = data[0].to(device)
        input_size = input.size(0)
        label = torch.full((input_size,), y_true, dtype=torch.float, device=device)
        output = modelDis(input).view(-1)
        lossDis_true = criterion(output, label)
        lossDis_true.backward()
        D_out = output.mean().item()
        noise = torch.randn(input_size, latent_dim, 1, 1, device=device)
        mislead = modelGen(noise)
        label.fill_(y_fake)
        output = modelDis(mislead.detach()).view(-1)
        lossDis_ad = criterion(output, label)
        lossDis_ad.backward()
        DG1 = output.mean().item()
        lossDis = lossDis_true + lossDis_ad
        optimDis.step()
        modelGen.zero_grad()
        label.fill_(y_true)
        output = modelDis(mislead).view(-1)
        lossG = criterion(output, label)
        lossG.backward()
        DG2 = output.mean().item()
        optimGen.step()

        if num_batch % 50 == 0:
            print('[%d/%d][%d/%d]\tLoss_D: %.4f\tLoss_G: %.4f\tD(x): %.4f\tD(G(z)): %.4f / %.4f'
#                   % (epoch, epochs, num_batch, len(dataloader),
                     lossDis.item(), lossG.item(), D_out, DG1, DG2))

        list_Gen.append(lossG.item())
        list_Dis.append(lossDis.item())

        if (check % 500 == 0) or ((epoch == epochs-1) and (num_batch == len(dataloader)-1)):
            with torch.no_grad():
                fake = modelGen(noise).detach().cpu()
            img_list.append(vutils.make_grid(mislead, padding=2, normalize=True))

        check += 1
    if epoch == 0 or epoch == epochs//2 or epoch == epochs-1:
        fig = plt.figure(figsize=(5, 5))
        plt.axis("off")
        plt.imshow(np.transpose(img_list[-1], (1, 2, 0)))
        plt.title("generate the images For noise vectors - Epoch {}".format(epoch))
        plt.show()

plot_loss(list_Gen,list_Dis)

true_img = next(iter(dataloader))
plt.figure(figsize=(15,15))
plt.subplot(1,2,1)
plt.title("Real Image")
plt.axis("off")
plt.imshow(np.transpose(vutils.make_grid(true_img[0].to(device)[:10], padding=5, normalize=True).cpu(),(1,2,0)))

plt.subplot(1,2,2)
plt.title("Fake Image")
plt.imshow(np.transpose(img_list[-1],(1,2,0)))
plt.axis("off")
plt.show()

fig = plt.figure(figsize=(5, 5))
plt.axis("off")
ims = [[plt.imshow(np.transpose(i,(1,2,0)), animated=True)] for i in img_list]
ani = animation.ArtistAnimation(fig, ims, interval=1000, repeat_delay=1000, blit=True)

HTML(ani.to_jshtml())